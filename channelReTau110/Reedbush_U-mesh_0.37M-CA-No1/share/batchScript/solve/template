#!/bin/bash

if [ -z "${PBS_JOBID+x}" ] ; then
    PBS_JOBID=$1
else
    cd $PBS_O_WORKDIR
fi

CASE_NAME=${PBS_JOBNAME}
PPN=${CASE_NAME%%-*};CASE_NAME=${CASE_NAME#*-}
PPN=${PPN#n}
FOAM_VERSION=${CASE_NAME%%-*};CASE_NAME=${CASE_NAME#*-}
COMPILER_TYPE=${CASE_NAME%%-*};CASE_NAME=${CASE_NAME#*-}
COMPILER=${CASE_NAME%%-*};CASE_NAME=${CASE_NAME#*-}
COMPILE_OPTION=${CASE_NAME%%-*};CASE_NAME=${CASE_NAME#*-}
MPLIB=${CASE_NAME%%-*};CASE_NAME=${CASE_NAME#*-}
PROFILER=${CASE_NAME%%-*};CASE_NAME=${CASE_NAME#*-}

export MPI_BUFFER_SIZE=20000000
. /etc/profile.d/modules.sh
module purge
module load pbsutils

case $COMPILER_TYPE in
    ThirdParty)
	;;
    system)
	case "$COMPILER" in
	    Gcc5_4_0)
		module load gnu/gcc_5.4.0
		module load intel-vtune/17.3.0.510739
		;;
	    Icc16_0_4_258)
		module load intel/16.0.4.258
		module load intel-vtune/17.1.0.486011
		;;
	    Icc17_0_1_132)
		module load intel/17.0.1.132
		module load intel-vtune/17.1.0.486011
		;;
	    Icc17_0_2_174)
		module load intel/17.0.2.174
		module load intel-vtune/17.2.0.499904
		;;
	    Icc17_0_4_196)
		module load intel/17.0.4.196
		module load intel-vtune/17.3.0.510739
		;;
	    *)
		;;
	esac	
	;;
    *)
	;;
esac

export VT_ROOT=$VTUNE_AMPLIFIER_XE_2017_DIR

case $MPLIB in
    SYSTEMOPENMPI2_0_2)
	case "$COMPILER" in
	    Gcc*)
		module load openmpi/2.0.2/gnu
		;;
	    Icc*)
		module load openmpi/2.0.2/intel
		;;
	esac	
	;;
    SYSTEMOPENMPI2_0_3)
	case "$COMPILER" in
	    Gcc*)
		module load openmpi/2.0.3/gnu
		;;
	    Icc*)
		module load openmpi/2.0.3/intel
		;;
	esac	
	;;
    SYSTEMOPENMPI2_1_1)
	case "$COMPILER" in
	    Gcc*)
		module load openmpi/2.1.1/gnu
		;;
	    Icc*)
		module load openmpi/2.1.1/intel
		;;
	esac	
	;;
    SGIMPI2_14)
	module load mpt/2.14
	;;
    SGIMPI2_15)
	module load mpt/2.15
	;;
    SGIMPI2_16)
	module load mpt/2.16
	;;
    INTELMPI5_1_3_210)
	module load intel-mpi/5.1.3.210
	;;
    INTELMPI5_1_3_258)
	module load intel-mpi/5.1.3.258
	;;
    INTELMPI2017_0_098)
	module load intel-mpi/2017.0.098
	;;
    INTELMPI2017_1_132)
	module load intel-mpi/2017.1.132
	;;
    INTELMPI2017_2_174)
	module load intel-mpi/2017.2.174
	;;
    INTELMPI2017_3_196)
	module load intel-mpi/2017.3.196
	;;
    MPIMVAPICH2_2_2)
	case "$COMPILER" in
	    Gcc*)
		module load mvapich2/2.2/gnu
		export MPI_ROOT=/lustre/app/mvapich2/2.2/ofed3.4/gnu
		;;
	    Icc*)
		module load mvapich2/2.2/intel
		export MPI_ROOT=/lustre/app/mvapich2/2.2/ofed3.4/intel
		;;
	esac	
	;;
    HPCXMPI1_9_7)
	case "$COMPILER" in
	    Gcc*)
		module load hpcx/1.9.7/gnu
		;;
	    Icc*)
		module load hpcx/1.9.7/intel
		;;
	esac	
	export MPI_ROOT=$MPI_HOME
	;;
    *)
	;;
esac

mpirun_command=mpirun
case $MPLIB in
    INTELMPI*)
	export MPI_ROOT=$I_MPI_ROOT
#	export I_MPI_DEBUG=5
	mpirun_command="$mpirun_command -env I_MPI_DYNAMIC_CONNECTION=0"
	;;
    SYSTEMOPENMPI2_1_1)
	mpirun_command="$mpirun_command --mca mpi_cuda_support 0"
	;;
    SGIMPI*)
	mpirun_command=mpiexec_mpt
	;;
    MPIMVAPICH*)
	export MV2_ENABLE_AFFINITY=0
	;;
esac

. ${HOME/home/lustre}/OpenFOAM/OpenFOAM-${FOAM_VERSION}/etc/bashrc \
WM_COMPILER_TYPE=$COMPILER_TYPE \
WM_COMPILER=$COMPILER \
WM_COMPILE_OPTION=$COMPILE_OPTION \
WM_MPLIB=$MPLIB

# Source tutorial run functions
#. $WM_PROJECT_DIR/bin/tools/RunFunctions

# Application name
application=pimpleFoam

log=log.${application}.${PBS_JOBID}

case "$PROFILER" in
    "a")
	mpirun_command="amplxe-cl -r ${log}.vtune -target-tmp-dir=/dev/shm --collect advanced-hotspots -- ${mpirun_command}"
	;;
    "p")
	mpirun_command="amplxe-cl -r ${log}.vtune -target-tmp-dir=/dev/shm --collect hotspots -- ${mpirun_command}"
	;;
    "s")
	module load perfsuite/1.1.4
	mpirun_command="${mpirun_command} psrun -f"
	;;
esac

(
    ulimit -a
    ulimit -c 0
    ulimit -a
    env
    echo $mpirun_command $application -parallel
    $mpirun_command $application -parallel
    rbstat -s ${PBS_JOBID}
) >&  ${log}
grep "^End" ${log} >& /dev/null && touch ${log}.done
